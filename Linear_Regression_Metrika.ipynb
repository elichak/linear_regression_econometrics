{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 893,
   "id": "2f030532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as sts\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "id": "2b32c4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.50516744,  4.10952221, 41.35163437, 92.42591004])"
      ]
     },
     "execution_count": 894,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_, y_, coef = make_regression(n_samples=100, n_features=4, coef=True, bias=35, noise=30)\n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "id": "4ddf2c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR_econ_model(object):\n",
    "    \"\"\"Класс линейной регрессии для эконометрических моделей\n",
    "    с проверками на значимость, интервалом предсказания, графиечксим представлением.\"\"\"\n",
    "    def __init__(self, X, y, standart = False):\n",
    "        if standart: # стандартизация переменных\n",
    "            self.regressors = (X - X.mean(axis = 0)) / X.std(axis = 0)\n",
    "            self.target_train = (y - y.mean()) / y.std()\n",
    "        else:\n",
    "        #регрессоры\n",
    "            self.regressors = X\n",
    "        #вектор целевой переменной\n",
    "            self.target_train = y\n",
    "        #матрица регрессоров\n",
    "        self.reg_corr_matrix = np.corrcoef(np.array([np.hsplit(X,\n",
    "                                                            indices_or_sections = X.shape[1])]).reshape(X.shape[1], -1))\n",
    "        if X.shape[1] > 1:\n",
    "            # вектор корреляций регрессоров с целевой переменной\n",
    "            self.C = np.corrcoef(x=np.array([np.hsplit(X,\n",
    "                            indices_or_sections = X.shape[1])]).reshape(X.shape[1], -1),\n",
    "                            y = self.target_train)[:-1,-1] \n",
    "            # линейный множественный коэффициент корреляции\n",
    "            self.ryX = self.C.T @ np.linalg.inv(self.reg_corr_matrix) @ self.C\n",
    "        \n",
    "        \n",
    "    def scatter_field(self):\n",
    "        \"\"\"График поля корреляции\"\"\"\n",
    "        try:\n",
    "            fig, ax = plt.subplots(figsize = (10, 7))\n",
    "            ax.scatter(self.regressors, self.target_train , color = 'r') \n",
    "        except ValueError:\n",
    "            print(\"You are trying to make a plot for more than one regressor!\")\n",
    "            ax.set_xlabel(xlabel = \"x\")\n",
    "            ax.set_ylabel(ylabel = \"y\")\n",
    "            ax.set_title(label = 'График поля корреляции')\n",
    "            ax.grid()\n",
    "            plt.show()\n",
    "        \n",
    "    \n",
    "    def fit(self, plot = False):\n",
    "        \"\"\"Обучение модели\"\"\"\n",
    "        I = np.ones(shape=(self.regressors.shape[0], 1)) # единичный вектор-столбец\n",
    "        X = np.hstack((I, self.regressors))\n",
    "        b = np.linalg.inv(np.dot(X.T, X)) @ X.T @ self.target_train # Аналитическое решение\n",
    "        # формат вывода: (b_0, b_1,...b_n)\n",
    "        if plot:\n",
    "            try:\n",
    "                fig, ax = plt.subplots(figsize = (10, 7))\n",
    "                y_hat = b[0] + b[1] * self.regressors\n",
    "                ax.scatter(self.regressors, self.target_train, color = 'r')\n",
    "            except ValueError:\n",
    "                print(\"You are trying to make a plot for more than one regressor!\")\n",
    "            else:\n",
    "                ax.plot(self.regressors, y_hat, label = 'Прогноз')\n",
    "                ax.set_xlabel(xlabel = \"X\")\n",
    "                ax.set_ylabel(ylabel = \"Y\")\n",
    "                ax.set_title(label = 'График МНК-оценки')\n",
    "                ax.grid()\n",
    "                plt.show()\n",
    "        self.coefs = b\n",
    "        return b\n",
    "    \n",
    "    def eq_significance(self, alpha = 0.05):\n",
    "        \"\"\"Значимость уравнения в целом\"\"\"\n",
    "        I = np.ones(shape=(self.regressors.shape[0], 1)) # единичный вектор-столбец\n",
    "        X = np.hstack((I, self.regressors))\n",
    "        y_hat = self.coefs @ X.T\n",
    "        # факторная вариация\n",
    "        Q_r = ((y_hat - self.target_train.mean())**2).sum()\n",
    "        # остаточная вариация\n",
    "        Q_e = ((y_hat - self.target_train)**2).sum()\n",
    "        S_r_squared = Q_r / self.regressors.shape[1] # факторная дисперсия\n",
    "        S_e_squared = Q_e / (self.regressors.shape[0] - self.regressors.shape[1] - 1)\n",
    "        F = S_r_squared / S_e_squared # расчетное значение F-критерия Фишера-Снедекора\n",
    "        F_alpha = sts.f(self.regressors.shape[1], self.regressors.shape[0] - self.regressors.shape[1] - 1).isf(alpha)\n",
    "        if F > F_alpha:\n",
    "            print(f\"{F} > {F_alpha}, следовательно уравнение значимо в целом\")\n",
    "        else:\n",
    "            print(f\"{F} < {F_alpha}, следовательно уравнение не значимо в целом\")\n",
    "        self.Q_r = Q_r\n",
    "        self.Q_e = Q_e\n",
    "        self.S_r_squared = S_r_squared\n",
    "        self.S_e_squared = S_e_squared\n",
    "        return Q_r, Q_e, S_r_squared, S_e_squared, F, F_alpha\n",
    "    \n",
    "    \n",
    "    def coef_significance(self, alpha = 0.05):\n",
    "        \"\"\"Значимость параметров\"\"\"\n",
    "        I = np.ones(shape=(self.regressors.shape[0], 1)) # единичный вектор-столбец\n",
    "        X = np.hstack((I, self.regressors))\n",
    "        Mat = np.linalg.inv(X.T @ X)\n",
    "        t_alpha = sts.t(self.regressors.shape[0] - self.regressors.shape[1] - 1).isf(alpha)\n",
    "        for j in range(X.shape[1]):\n",
    "            m_j = np.sqrt(self.S_e_squared * Mat[j][j])\n",
    "            t_stat_j = self.coefs[j] / m_j\n",
    "            if abs(t_stat_j) > t_alpha:\n",
    "                print(f\"Так как |t_stat_{j}| = {abs(t_stat_j)} > t_alpha = {t_alpha}, коэффициент b_{j} значим на уровне значимости { alpha}\")\n",
    "            else:\n",
    "                print(f\"Так как |t_stat_{j}| = {abs(t_stat_j)} <= t_alpha = {t_alpha}, коэффициент b_{j} не значим на уровне значимости { alpha} и равен нулю\")\n",
    "            print(m_j, Mat[j][j])\n",
    "            print(\"\\n\")\n",
    "            \n",
    "    def score(self):\n",
    "        \"\"\"Показатели качества\"\"\"\n",
    "        # коэффициент детерминации\n",
    "        R_squared = self.Q_r / (self.Q_e + self.Q_r)\n",
    "        # скорретированный коэффициент детерминации\n",
    "        R_squared_corrected = (self.regressors.shape[0] - self.regressors.shape[1] - 1) / (self.regressors.shape[0] - 1) * R_squared\n",
    "        I = np.ones(shape=(self.regressors.shape[0], 1)) # единичный вектор-столбец\n",
    "        X = np.hstack((I, self.regressors))\n",
    "        # предсказания на тренировочной выборке\n",
    "        y_hat = self.coefs @ X.T\n",
    "        # средняя ошибка аппроксимации\n",
    "        A = abs((self.target_train - y_hat)/self.target_train).sum() / (self.regressors.shape[0]) \n",
    "        print(f\" R^2 = {R_squared}\\n R^2_cor = {R_squared_corrected}\\n A = {A * 100}%\")\n",
    "        \n",
    "    def predict(self, X_predict, alpha = 0.05):\n",
    "        \"\"\"Предсказание\"\"\"\n",
    "        I = np.ones(shape=(self.regressors.shape[0], 1)) # единичный вектор-столбец\n",
    "        X = np.hstack((I, self.regressors))\n",
    "        y_p = np.dot(self.coefs, X_predict)\n",
    "        S_y_p = np.sqrt(1 + X_predict @ np.linalg.inv(X.T @ X) @ X_predict.T)\n",
    "        t_alpha = sts.t(self.regressors.shape[0] - self.regressors.shape[1] - 1).isf(alpha)\n",
    "        print(f\"Точечный прогноз = {y_p}\\n {alpha * 100}%-Доверительный интервал: ({y_p - S_y_p * t_alpha}, {y_p + S_y_p * t_alpha})\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "id": "34b4d96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[37. , 20. ],\n",
       "       [60. , 10. ],\n",
       "       [60. , 10. ],\n",
       "       [53. , 15. ],\n",
       "       [35. ,  8. ],\n",
       "       [30. , 15. ],\n",
       "       [43. ,  5. ],\n",
       "       [30. , 10. ],\n",
       "       [35. ,  3. ],\n",
       "       [32. ,  5. ],\n",
       "       [31. , 10. ],\n",
       "       [33. ,  5. ],\n",
       "       [53. ,  5. ],\n",
       "       [32. , 20. ],\n",
       "       [31. , 15. ],\n",
       "       [36. ,  5. ],\n",
       "       [48. , 15. ],\n",
       "       [55.5, 10. ],\n",
       "       [48. , 10. ],\n",
       "       [44.1, 25. ],\n",
       "       [80. , 10. ],\n",
       "       [60. , 12. ],\n",
       "       [50. , 15. ],\n",
       "       [54.6, 20. ],\n",
       "       [43. , 10. ],\n",
       "       [66. ,  5. ],\n",
       "       [53.5, 15. ],\n",
       "       [45. , 12. ],\n",
       "       [45. ,  5. ],\n",
       "       [50.6, 10. ]])"
      ]
     },
     "execution_count": 916,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.array([[30, 4.1],\n",
    "            [28, 3.1],\n",
    "             [34, 3.05],\n",
    "             [38, 3.2],\n",
    "             [39, 3.4],\n",
    "             [45, 3.05],\n",
    "             [54, 3.7]])\n",
    "y_test = np.array([23, 27, 31, 33, 34, 36, 37])\n",
    "y = np.array([13, 16.5, 17, 15, 14.2, 10.5, 23, 12, 15.6, 12.5, 11.3, 13, 21, 12, 11, 11, 22.5, 26, 18.5, 13.2, 25.8, 17, 18, 21, 14.5, 23, 19.5, 14.2, 13.3, 16.1])\n",
    "X1 = np.array([37, 60, 60, 53, 35, 30, 43, 30, 35, 32, 31, 33, 53, 32, 31, 36, 48, 55.5, 48, 44.1, 80, 60, 50, 54.6, 43, 66, 53.5, 45, 45, 50.6])\n",
    "X2 = np.array([20, 10, 10, 15, 8, 15, 5, 10, 3, 5, 10, 5, 5, 20, 15, 5, 15, 10, 10, 25, 10, 12, 15, 20, 10, 5, 15, 12, 5, 10])\n",
    "X = []\n",
    "for i in range(len(X1)):\n",
    "    X.append([X1[i], X2[i]])\n",
    "X = np.array(X); X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "id": "21bf13d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = LR_econ_model(X_test, y_test, standart=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "id": "cb366cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.99498448,  1.97843909],\n",
       "       [-1.23515315, -0.73706554],\n",
       "       [-0.51464714, -0.87284077],\n",
       "       [-0.03430981, -0.46551508],\n",
       "       [ 0.08577452,  0.07758585],\n",
       "       [ 0.80628053, -0.87284077],\n",
       "       [ 1.88703953,  0.89223724]])"
      ]
     },
     "execution_count": 918,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "id": "91febeab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.05623381],\n",
       "       [0.05623381, 1.        ]])"
      ]
     },
     "execution_count": 919,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.reg_corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "id": "a47ec9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9519073237397925"
      ]
     },
     "execution_count": 920,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.ryX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "id": "aa5c65d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.55111512e-17,  8.97351421e-01, -4.36743918e-01])"
      ]
     },
     "execution_count": 921,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "id": "9f955415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.586373550494294 > 6.944271909999155, следовательно уравнение значимо в целом\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6.663351266178543,\n",
       " 0.33664873382145616,\n",
       " 3.3316756330892714,\n",
       " 0.08416218345536404,\n",
       " 39.586373550494294,\n",
       " 6.944271909999155)"
      ]
     },
     "execution_count": 922,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.eq_significance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "id": "edd33c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Так как |t_stat_0| = 5.062566688133451e-16 <= t_alpha = 2.1318467813362907, коэффициент b_0 не значим на уровне значимости 0.05 и равен нулю\n",
      "0.10965021233473288 0.14285714285714285\n",
      "\n",
      "\n",
      "Так как |t_stat_1| = 8.170813879622587 > t_alpha = 2.1318467813362907, коэффициент b_1 значим на уровне значимости 0.05\n",
      "0.1098239948358454 0.1433103247386707\n",
      "\n",
      "\n",
      "Так как |t_stat_2| = 3.9767622563260177 > t_alpha = 2.1318467813362907, коэффициент b_2 значим на уровне значимости 0.05\n",
      "0.1098239948358454 0.1433103247386707\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "obj.coef_significance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "id": "76e0e1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " R^2 = 0.9519073237397919\n",
      " R^2_cor = 0.6346048824931946\n",
      " A = 31.75136419623653%\n"
     ]
    }
   ],
   "source": [
    "obj.score()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
